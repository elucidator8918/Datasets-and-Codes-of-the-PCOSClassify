{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing & Importing all the necessary packages\n",
    "\n",
    "Update system packages, install `libgl1`, and install the `openpyxl` library for handling Excel files\n",
    "\n",
    "- **`albumentations`**: Library for image augmentation to enhance training data diversity.\n",
    "- **`sweetviz`**: Generates high-density visualizations of pandas DataFrames for quick data analysis.\n",
    "- **`grad-cam`**: Visualizes important image regions for CNN predictions using Grad-CAM.\n",
    "- **`lime`**: Provides local explanations for machine learning model predictions.\n",
    "- **`pandas_profiling`**: Creates detailed reports of pandas DataFrames for exploratory data analysis.\n",
    "- **`shap`**: Explains model predictions by attributing feature contributions using Shapley values.\n",
    "- **`Keras-Preprocessing`**: Offers utilities for preprocessing data, including image and text transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!sudo apt-get update && apt-get install libgl1 -y\n",
    "!pip install openpyxl -q\n",
    "!pip install albumentations sweetviz grad-cam lime pandas_profiling shap Keras-Preprocessing -q\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             confusion_matrix, classification_report, roc_curve, \n",
    "                             roc_auc_score, f1_score, matthews_corrcoef, hamming_loss, \n",
    "                             precision_recall_curve)\n",
    "\n",
    "# Import classifiers and utilities from scikit-learn for building and managing machine learning models:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "\n",
    "# Image processing and augmentation\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import (load_img, img_to_array, ImageDataGenerator)\n",
    "import albumentations as A\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "import skimage.io\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Dense, BatchNormalization, Flatten, Conv2D, \n",
    "                                     MaxPooling2D, Dropout, GlobalAveragePooling2D, \n",
    "                                     LeakyReLU, Activation)\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, SGD, Adagrad, Adadelta, RMSprop, Nadam\n",
    "from tensorflow.keras.callbacks import (TensorBoard, ModelCheckpoint, EarlyStopping, \n",
    "                                        History, ReduceLROnPlateau, CSVLogger, LearningRateScheduler)\n",
    "from tensorflow.keras.applications import (VGG19, ResNet152V2, ResNet50V2, ResNet101V2, \n",
    "                                           InceptionV3, InceptionResNetV2, MobileNetV2, \n",
    "                                           DenseNet169, NASNetMobile, EfficientNetB7, ConvNeXtBase)\n",
    "\n",
    "# Explanation and visualization tools\n",
    "from lime import lime_image\n",
    "import shap\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# IPython magic commands for TensorBoard\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "\n",
    "# Set plot parameters\n",
    "params = {'figure.figsize': (16, 8),\n",
    "          'legend.fontsize': 16,\n",
    "          'legend.handlelength': 2,\n",
    "          'axes.titlesize': 'large'}\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Cleaning\n",
    "\n",
    "Load class labels from an Excel file, binary test labels from a CSV, clean the class labels DataFrame by removing empty rows and columns, and display the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la1=pd.read_excel('/workspace/anushka saini/train_val/multilabelpcos.xlsx')\n",
    "la1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la2 = pd.read_csv('/workspace/anushka saini/test/test_label_multi.csv')\n",
    "la2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = la1.dropna(how='all').dropna(how='all', axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validate Split\n",
    "\n",
    "Split the DataFrame into training and validation sets based on specified percentages, using optional random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_split(df, train_percent=.8, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    # test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = train_validate_split(df)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image and Label Preparation\n",
    "\n",
    "Map labels, load and preprocess images for training, validation, and testing, and display shapes of image arrays and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train[[\"Round and Thin\", \"Cumulus oophorous\", \"Corpus luteum\", \"Hemorrhagic ovarian cyst\", \"Hemorrhagic corpus luteum\", \"Endometrioma\", \"serous cystadenoma\", \"Serous cystadenocarcinoma\", \"Mucinous cystadenoma\", \"Mucinous cystadenocarcinoma\", \"Dermoid cyst\", \"Dermoid plug\", \"Rokitansky nodule\", \"Dermoid mesh\", \"Dot dash pattern\", \"Floating balls sign\", \"Ovarian fibroma\", \"Ovarian thecoma\", \"Metastasis\", \"Para ovarian cyst\", \"Polycystic ovary\", \"Ovarian hyperstimulation syndrome\", \"Ovarian torsion\", \"Thick hyperechoic margin\", \"Vaginal ultrasound\", \"Transvaginal ultrasound\", \"Gestational sac\", \"Foetus\", \"Chocolate cyst\", \"Cervix\", \"Urinary bladder\", \"Polyp\", \"Cervical cyst\"]].values\n",
    "train_image_paths = [os.path.join('/workspace/anushka saini/train_val/images', filename) for filename in train['ImagePath']] #to change when using GPU. similarly for validate and test\n",
    "train_images = []\n",
    "for train_image_path in train_image_paths:\n",
    "    image = load_img(train_image_path, target_size=(300, 300)) # change this when you run on GPU. 320X320 rahegi\n",
    "    image = img_to_array(image) / 255.0  # Normalize pixel values between 0 and 1\n",
    "    train_images.append(image)\n",
    "train_images = np.array(train_images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_labels = validate[[\"Round and Thin\", \"Cumulus oophorous\", \"Corpus luteum\", \"Hemorrhagic ovarian cyst\", \"Hemorrhagic corpus luteum\", \"Endometrioma\", \"serous cystadenoma\", \"Serous cystadenocarcinoma\", \"Mucinous cystadenoma\", \"Mucinous cystadenocarcinoma\", \"Dermoid cyst\", \"Dermoid plug\", \"Rokitansky nodule\", \"Dermoid mesh\", \"Dot dash pattern\", \"Floating balls sign\", \"Ovarian fibroma\", \"Ovarian thecoma\", \"Metastasis\", \"Para ovarian cyst\", \"Polycystic ovary\", \"Ovarian hyperstimulation syndrome\", \"Ovarian torsion\", \"Thick hyperechoic margin\", \"Vaginal ultrasound\", \"Transvaginal ultrasound\", \"Gestational sac\", \"Foetus\", \"Chocolate cyst\", \"Cervix\", \"Urinary bladder\", \"Polyp\", \"Cervical cyst\"]].values\n",
    "validate_image_paths = [os.path.join('/workspace/anushka saini/train_val/images', filename) for filename in validate['ImagePath']]\n",
    "validate_images = []\n",
    "for validate_image_path in validate_image_paths:\n",
    "    image = load_img(validate_image_path, target_size=(300, 300)) # change this when you run on GPU\n",
    "    image = img_to_array(image) / 255.0  # Normalize pixel values between 0 and 1\n",
    "    validate_images.append(image)\n",
    "validate_images = np.array(validate_images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = la2[[\"Round and Thin\", \"Cumulus oophorous\", \"Corpus luteum\", \"Hemorrhagic ovarian cyst\", \"Hemorrhagic corpus luteum\", \"Endometrioma\", \"serous cystadenoma\", \"Serous cystadenocarcinoma\", \"Mucinous cystadenoma\", \"Mucinous cystadenocarcinoma\", \"Dermoid cyst\", \"Dermoid plug\", \"Rokitansky nodule\", \"Dermoid mesh\", \"Dot dash pattern\", \"Floating balls sign\", \"Ovarian fibroma\", \"Ovarian thecoma\", \"Metastasis\", \"Para ovarian cyst\", \"Polycystic ovary\", \"Ovarian hyperstimulation syndrome\", \"Ovarian torsion\", \"Thick hyperechoic margin\", \"Vaginal ultrasound\", \"Transvaginal ultrasound\", \"Gestational sac\", \"Foetus\", \"Chocolate cyst\", \"Cervix\", \"Urinary bladder\", \"Polyp\", \"Cervical cyst\"]].values\n",
    "test_image_paths = [os.path.join('/workspace/anushka saini/test/images', filename) for filename in la2['imagePath']]\n",
    "test_images = []\n",
    "for test_image_path in test_image_paths:\n",
    "    image = load_img(test_image_path, target_size=(300, 300)) # change this when you run on GPU\n",
    "    image = img_to_array(image) / 255.0  # Normalize pixel values between 0 and 1\n",
    "    test_images.append(image)\n",
    "test_images = np.array(test_images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reshaping for Classifier\n",
    "\n",
    "Reshape training, validation, and test images into flat arrays for classifier input and print their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset 80% for classifier fitting\n",
    "x_train = train_images.reshape(train_images.shape[0], -1)\n",
    "y_train = train_labels\n",
    "# print(x_train)\n",
    "# print(y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation data 20% for classifier prediction\n",
    "x_test_internal = validate_images.reshape(validate_images.shape[0], -1)\n",
    "y_test_internal = validate_labels\n",
    "# print(y_test_internal)\n",
    "print(x_test_internal.shape)\n",
    "print(y_test_internal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_external = test_images.reshape(test_images.shape[0], -1)\n",
    "y_test_external = test_labels\n",
    "# print(y_test_external)\n",
    "print(x_test_external.shape)\n",
    "print(y_test_external.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "\n",
    "Train Multiple classifiers on the training data, then evaluate and print accuracy, balanced accuracy, weighted F1 score, weighted recall, weighted precision, and weighted Jaccard score for both internal and external test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf0 = RandomForestClassifier().fit(x_train, y_train)\n",
    "ypred0 = clf0.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred0) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred0) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred0, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred0, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred0, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred0, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = clf0.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred1) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred1) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred1, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred1, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred1, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred1, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RidgeClassifier().fit(x_train, y_train)\n",
    "ypred2 = clf1.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred2) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred2) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred2, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred2, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred2, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred2, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred3 = clf1.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred3) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred3) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred3, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred3, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred3, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred3, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree = ExtraTreeClassifier(random_state=0)\n",
    "clf2 = BaggingClassifier(extra_tree, random_state=0).fit(x_train, y_train)\n",
    "ypred4 = clf2.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred4) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred4) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred4, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred4, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred4, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred4, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred5 = clf2.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred5) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred5) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred5, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred5, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred5, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred5, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = MLPClassifier(random_state=1, max_iter=300).fit(x_train, y_train)\n",
    "ypred6 = clf3.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred6) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred6) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred6, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred6, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred6, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred6, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred7 = clf3.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred7) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred7) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred7, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred7, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred7, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred7, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "clf4 = neigh.fit(x_train, y_train)\n",
    "ypred8 = clf4.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred8) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred8) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred8, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred8, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred8, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred8, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred9 = clf4.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred9) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred9) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred9, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred9, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred9, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred9, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = DecisionTreeClassifier(random_state=0)\n",
    "clf5 = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "ypred10 = clf5.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred10) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred10) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred10, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred10, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred10, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred10, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred11 = clf5.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred11) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred11) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred11, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred11, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred11, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred11, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = SVC(kernel='rbf',gamma='auto').fit(x_train,y_train)\n",
    "ypred12 = clf6.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred12) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred12) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred12, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred12, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred12, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred12, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred13 = clf6.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred13) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred13) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred13, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred13, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred13, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred13, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7 = GaussianNB().fit(x_train,y_train)\n",
    "ypred14 = clf7.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred14) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred14) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred14, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred14, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred14, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred14, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred15 = clf7.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred15) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred15) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred15, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred15, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred15, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred15, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf8 = LogisticRegression().fit(x_train,y_train)\n",
    "ypred16 = clf8.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred16) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred16) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred16, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred16, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred16, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred16, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred17 = clf8.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred17) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred17) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred17, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred17, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred17, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred17, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf9 = AdaBoostClassifier().fit(x_train,y_train)\n",
    "ypred18 = clf9.predict(x_test_internal)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_internal, ypred18) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_internal, ypred18) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_internal, ypred18, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_internal, ypred18, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_internal, ypred18, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_internal, ypred18, average='weighted') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred19 = clf9.predict(x_test_external)\n",
    "print(\"Accuracy is\", metrics.accuracy_score(y_test_external, ypred19) * 100)\n",
    "print(\"Balanced accuracy is\", metrics.balanced_accuracy_score(y_test_external, ypred19) * 100)\n",
    "print(\"Weighted f1 score is\", metrics.f1_score(y_test_external, ypred19, average='weighted') * 100)\n",
    "print(\"Weighted recall is\", metrics.recall_score(y_test_external, ypred19, average='weighted') * 100)\n",
    "print(\"Weighted precision is\", metrics.precision_score(y_test_external, ypred19, average='weighted') * 100)\n",
    "print(\"Weighted Jaccard score is\", metrics.jaccard_score(y_test_external, ypred19, average='weighted') * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
